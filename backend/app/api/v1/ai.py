from fastapi import APIRouter, Depends, HTTPException, status, Body
from fastapi.responses import StreamingResponse
from sqlmodel import Session
from typing import Dict, Any, Optional
import asyncio
import json
import google.generativeai as genai
from app.core.database import get_session
from app.core.auth import AuthService
from app.core.config import settings
from pydantic import BaseModel

router = APIRouter()

# Gemini API ì„¤ì •
genai.configure(api_key=settings.gemini_api_key)
model = genai.GenerativeModel('gemini-1.5-flash')

async def call_gemini_api(message: str) -> str:
    """Gemini API í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„)"""
    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(ì—­í• /ê¶Œí•œ/ê°œì¸ì •ë³´ ì œí•œ ì—†ìŒ) ì¶”ê°€
        system_prompt = """
        ë„ˆëŠ” í•™ì› ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ê´€ë¦¬ì ì „ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤.
        ì´ ì‹œìŠ¤í…œì€ ë‚´ë¶€ ê´€ë¦¬ìë§Œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë©°, í•™ìƒ/ê°•ì‚¬/êµì¬ ë“± ëª¨ë“  ë°ì´í„°ë¥¼ ììœ ë¡­ê²Œ ì¡°íšŒ/ìˆ˜ì •/ì‚­ì œí•  ìˆ˜ ìˆë‹¤.
        ê°œì¸ì •ë³´ ë³´í˜¸ëŠ” ì™¸ë¶€ ë…¸ì¶œì—ë§Œ í•´ë‹¹ë˜ë©°, ë‚´ë¶€ ìš”ì²­ì—ëŠ” ì œí•œì„ ë‘ì§€ ì•ŠëŠ”ë‹¤.
        ê´€ë¦¬ì ìš”ì²­ì—ëŠ” í•™ìƒ ëª©ë¡, ê°•ì‚¬ ëª©ë¡, êµì¬ ì •ë³´ ë“± ëª¨ë“  ë°ì´í„°ë¥¼ ìƒì„¸í•˜ê²Œ ì œê³µí•´ì•¼ í•œë‹¤.
        """
        prompt = f"""
        {system_prompt}
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: {message}

        ë‹µë³€ í˜•ì‹:
        1. ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
        2. ì¶”ê°€ì ì¸ ë„ì›€ë§ì´ë‚˜ ì œì•ˆì‚¬í•­
        3. ê´€ë ¨ëœ ì‹œìŠ¤í…œ ê¸°ëŠ¥ ì•ˆë‚´
        """
        # Gemini API í˜¸ì¶œ
        response = model.generate_content(prompt)
        if response.text:
            return response.text
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return f"AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

async def call_gemini_api_stream(message: str):
    """Gemini API ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ"""
    try:
        # í”„ë¡¬í”„íŠ¸ ì„¤ì •
        prompt = f"""
        ë‹¹ì‹ ì€ í•™ì› ê´€ë¦¬ ì‹œìŠ¤í…œì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        
        ì‚¬ìš©ì ì§ˆë¬¸: {message}
        
        ë‹µë³€ í˜•ì‹:
        1. ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
        2. ì¶”ê°€ì ì¸ ë„ì›€ë§ì´ë‚˜ ì œì•ˆì‚¬í•­
        3. ê´€ë ¨ëœ ì‹œìŠ¤í…œ ê¸°ëŠ¥ ì•ˆë‚´
        """
        
        # Gemini API ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
        response = model.generate_content(prompt, stream=True)
        
        for chunk in response:
            if chunk.text:
                yield f"data: {json.dumps({'content': chunk.text})}\n\n"
                await asyncio.sleep(0.1)  # ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì§€ì—°
                
    except Exception as e:
        print(f"Gemini API ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
        yield f"data: {json.dumps({'error': f'AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(e)}'})}\n\n"

def generate_temp_response(message: str) -> str:
    """ì„ì‹œ ì‘ë‹µ ìƒì„± (Gemini API ì—†ì´ í…ŒìŠ¤íŠ¸ìš©)"""
    lower_message = message.lower()
    
    if 'í•™ìƒ' in lower_message or 'student' in lower_message:
        return '''í•™ìƒ ê´€ë¦¬ ê¸°ëŠ¥ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!

ğŸ“š ì£¼ìš” ê¸°ëŠ¥:
â€¢ í•™ìƒ ë“±ë¡ ë° ì •ë³´ ê´€ë¦¬
â€¢ ì¶œì„ ê´€ë¦¬ ë° í†µê³„
â€¢ ì„±ì  ê´€ë¦¬ ë° ë¶„ì„
â€¢ ìˆ˜ê°•ë£Œ ê´€ë¦¬

ğŸ’¡ ì‚¬ìš© ë°©ë²•:
ëŒ€ì‹œë³´ë“œì—ì„œ "í•™ìƒ ê´€ë¦¬" ë©”ë‰´ë¥¼ í´ë¦­í•˜ì‹œë©´ í•™ìƒ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆ í•™ìƒì„ ë“±ë¡í•˜ê±°ë‚˜ ê¸°ì¡´ í•™ìƒ ì •ë³´ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ì¶”ê°€ ë„ì›€:
íŠ¹ì • í•™ìƒì— ëŒ€í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ "ê¹€ì² ìˆ˜ í•™ìƒ ì •ë³´ ë³´ì—¬ì¤˜"ì™€ ê°™ì´ ë§ì”€í•´ì£¼ì„¸ìš”.'''
    
    elif 'ê°•ì‚¬' in lower_message or 'teacher' in lower_message:
        return '''ê°•ì‚¬ ê´€ë¦¬ ê¸°ëŠ¥ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!

ğŸ‘¨â€ğŸ« ì£¼ìš” ê¸°ëŠ¥:
â€¢ ê°•ì‚¬ ë“±ë¡ ë° í”„ë¡œí•„ ê´€ë¦¬
â€¢ ê°•ì˜ ìŠ¤ì¼€ì¤„ ê´€ë¦¬
â€¢ ê°•ì˜ í˜„í™© ë° í†µê³„
â€¢ ê°•ì‚¬ë³„ í•™ìƒ ê´€ë¦¬

ğŸ’¡ ì‚¬ìš© ë°©ë²•:
ëŒ€ì‹œë³´ë“œì—ì„œ "ê°•ì‚¬ ê´€ë¦¬" ë©”ë‰´ë¥¼ í´ë¦­í•˜ì‹œë©´ ê°•ì‚¬ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆ ê°•ì‚¬ë¥¼ ë“±ë¡í•˜ê±°ë‚˜ ìŠ¤ì¼€ì¤„ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ì¶”ê°€ ë„ì›€:
íŠ¹ì • ê°•ì‚¬ì˜ ìŠ¤ì¼€ì¤„ì´ í•„ìš”í•˜ì‹œë©´ "ì´ì˜í¬ ê°•ì‚¬ ìŠ¤ì¼€ì¤„ í™•ì¸"ê³¼ ê°™ì´ ë§ì”€í•´ì£¼ì„¸ìš”.'''
    
    elif 'êµì¬' in lower_message or 'material' in lower_message:
        return '''êµì¬ ê´€ë¦¬ ê¸°ëŠ¥ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!

ğŸ“– ì£¼ìš” ê¸°ëŠ¥:
â€¢ êµì¬ ë“±ë¡ ë° ì •ë³´ ê´€ë¦¬
â€¢ ì¬ê³  ê´€ë¦¬ ë° ì•Œë¦¼
â€¢ êµì¬ë³„ í•™ìƒ í˜„í™©
â€¢ êµì¬ ì‚¬ìš© í†µê³„

ğŸ’¡ ì‚¬ìš© ë°©ë²•:
ëŒ€ì‹œë³´ë“œì—ì„œ "êµì¬ ê´€ë¦¬" ë©”ë‰´ë¥¼ í´ë¦­í•˜ì‹œë©´ êµì¬ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆ êµì¬ë¥¼ ë“±ë¡í•˜ê±°ë‚˜ ì¬ê³ ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ì¶”ê°€ ë„ì›€:
íŠ¹ì • êµì¬ì˜ ì¬ê³ ê°€ í•„ìš”í•˜ì‹œë©´ "ìˆ˜í•™ êµì¬ ì¬ê³  í™•ì¸"ê³¼ ê°™ì´ ë§ì”€í•´ì£¼ì„¸ìš”.'''
    
    elif 'ìˆ˜ê°•ë£Œ' in lower_message or 'tuition' in lower_message:
        return '''ìˆ˜ê°•ë£Œ ê´€ë¦¬ ê¸°ëŠ¥ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!

ğŸ’° ì£¼ìš” ê¸°ëŠ¥:
â€¢ ìˆ˜ê°•ë£Œ ë‚©ë¶€ í˜„í™© ê´€ë¦¬
â€¢ ë¯¸ë‚© í•™ìƒ ëª©ë¡ ë° ì•Œë¦¼
â€¢ ë‚©ë¶€ ì¼ì • ê´€ë¦¬
â€¢ ìˆ˜ê°•ë£Œ í†µê³„ ë° ë¦¬í¬íŠ¸

ğŸ’¡ ì‚¬ìš© ë°©ë²•:
í˜„ì¬ ìˆ˜ê°•ë£Œ ê´€ë¦¬ ê¸°ëŠ¥ì€ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. ê³§ í•™ìƒë³„ ìˆ˜ê°•ë£Œ ê´€ë¦¬, ë‚©ë¶€ í˜„í™© ì¶”ì , ë¯¸ë‚© ì•Œë¦¼ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•  ì˜ˆì •ì…ë‹ˆë‹¤.

ğŸ” ì¶”ê°€ ë„ì›€:
ë¯¸ë‚© í•™ìƒ ëª©ë¡ì´ í•„ìš”í•˜ì‹œë©´ "ë¯¸ë‚© í•™ìƒ ëª©ë¡"ê³¼ ê°™ì´ ë§ì”€í•´ì£¼ì„¸ìš”.'''
    
    elif 'ì•ˆë…•' in lower_message or 'hello' in lower_message:
        return '''ì•ˆë…•í•˜ì„¸ìš”! í•™ì› ê´€ë¦¬ ì‹œìŠ¤í…œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰

ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ í•™ì› ê´€ë¦¬ì— í•„ìš”í•œ ëª¨ë“  ì •ë³´ë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤.

ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥:
â€¢ í•™ìƒ ê´€ë¦¬ (ë“±ë¡, ì •ë³´ ìˆ˜ì •, ì¶œì„ ê´€ë¦¬)
â€¢ ê°•ì‚¬ ê´€ë¦¬ (ë“±ë¡, ìŠ¤ì¼€ì¤„ ê´€ë¦¬)
â€¢ êµì¬ ê´€ë¦¬ (ë“±ë¡, ì¬ê³  ê´€ë¦¬)
â€¢ ìˆ˜ê°•ë£Œ ê´€ë¦¬ (ë‚©ë¶€ í˜„í™©, ë¯¸ë‚© ê´€ë¦¬)

ğŸ’¬ ì§ˆë¬¸ ì˜ˆì‹œ:
- "í•™ìƒ ê´€ë¦¬ ë°©ë²• ì•Œë ¤ì¤˜"
- "ê°•ì‚¬ ìŠ¤ì¼€ì¤„ í™•ì¸"
- "êµì¬ ì¬ê³  í˜„í™©"
- "ë¯¸ë‚© í•™ìƒ ëª©ë¡"

ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š'''
    
    else:
        return '''ì•ˆë…•í•˜ì„¸ìš”! í•™ì› ê´€ë¦¬ ì‹œìŠ¤í…œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ğŸ¤–

í˜„ì¬ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

ğŸ“š í•™ìƒ ê´€ë¦¬
ğŸ‘¨â€ğŸ« ê°•ì‚¬ ê´€ë¦¬  
ğŸ“– êµì¬ ê´€ë¦¬
ğŸ’° ìˆ˜ê°•ë£Œ ê´€ë¦¬

ì˜ˆì‹œ ì§ˆë¬¸:
â€¢ "í•™ìƒ ë“±ë¡ ë°©ë²• ì•Œë ¤ì¤˜"
â€¢ "ê°•ì‚¬ ìŠ¤ì¼€ì¤„ í™•ì¸"
â€¢ "êµì¬ ì¬ê³  í˜„í™©"
â€¢ "ìˆ˜ê°•ë£Œ ë‚©ë¶€ í˜„í™©"

ì–´ë–¤ ê¸°ëŠ¥ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ğŸ˜Š'''

class ChatRequest(BaseModel):
    message: str

@router.post("/chat", summary="AI ì±„íŒ…")
async def chat_with_ai(
    message: str = Body(...),
    session: Session = Depends(get_session),
    current_user = Depends(AuthService.get_current_active_user)
):
    """AIì™€ ì±„íŒ…í•©ë‹ˆë‹¤."""
    try:
        response = await call_gemini_api(message)
        return {"response": response, "user_id": current_user.id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(e)}")

@router.post("/chat/test", summary="AI ì±„íŒ… í…ŒìŠ¤íŠ¸ (ì¸ì¦ ì—†ìŒ)")
async def chat_with_ai_test(req: ChatRequest):
    """AIì™€ ì±„íŒ…í•©ë‹ˆë‹¤. (í…ŒìŠ¤íŠ¸ìš©, ì¸ì¦ ì—†ìŒ)"""
    try:
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë¡œê·¸
        key = settings.gemini_api_key
        print(f"[DEBUG] GEMINI_API_KEY: {key[:4]}...{key[-4:]}")
        # Gemini APIê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‹¤ì œ API í˜¸ì¶œ, ì—†ìœ¼ë©´ ì„ì‹œ ì‘ë‹µ
        if key and key != "your-gemini-api-key":
            response = await call_gemini_api(req.message)
        else:
            response = generate_temp_response(req.message)
        return {"response": response, "status": "success"}
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì„ì‹œ ì‘ë‹µ ì œê³µ
        return {"response": f"ì˜¤ë¥˜: {str(e)}", "status": "error"}

@router.post("/chat/stream", summary="AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë°")
async def chat_with_ai_stream(
    message: str = Body(...),
    session: Session = Depends(get_session),
    current_user = Depends(AuthService.get_current_active_user)
):
    """AIì™€ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…í•©ë‹ˆë‹¤."""
    return StreamingResponse(
        call_gemini_api_stream(message),
        media_type="text/plain",
        headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
    )

@router.post("/analyze", summary="í•™ìŠµ ë¶„ì„")
async def analyze_learning(
    data: Dict[str, Any] = Body(...),
    session: Session = Depends(get_session),
    current_user = Depends(AuthService.get_current_active_user)
):
    """í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        # í•™ìŠµ ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
        analysis_prompt = f"""
        ë‹¤ìŒ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í•™ìƒì˜ ê°•ì , ì•½ì , ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.
        
        í•™ìŠµ ë°ì´í„°: {json.dumps(data, ensure_ascii=False)}
        
        ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
        1. ê°•ì  (strengths): í•™ìƒì´ ì˜í•˜ëŠ” ì˜ì—­
        2. ì•½ì  (weaknesses): ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­
        3. ê¶Œì¥ì‚¬í•­ (recommendations): êµ¬ì²´ì ì¸ í•™ìŠµ ë°©ì•ˆ
        4. ì§„í–‰ë„ ì ìˆ˜ (progress_score): 0-100 ì‚¬ì´ì˜ ì ìˆ˜
        """
        
        # Gemini APIë¡œ ë¶„ì„ ìˆ˜í–‰
        response = model.generate_content(analysis_prompt)
        
        if response.text:
            # ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
            try:
                # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
                analysis_text = response.text
                
                # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
                analysis_result = {
                    "strengths": ["ìˆ˜í•™", "ê³¼í•™"],  # ê¸°ë³¸ê°’
                    "weaknesses": ["ì˜ì–´"],  # ê¸°ë³¸ê°’
                    "recommendations": ["ì˜ì–´ í•™ìŠµ ì‹œê°„ì„ ëŠ˜ë¦¬ì„¸ìš”"],  # ê¸°ë³¸ê°’
                    "progress_score": 75,  # ê¸°ë³¸ê°’
                    "ai_analysis": analysis_text  # AI ë¶„ì„ í…ìŠ¤íŠ¸ í¬í•¨
                }
                
                return analysis_result
            except Exception as parse_error:
                return {
                    "strengths": ["ìˆ˜í•™", "ê³¼í•™"],
                    "weaknesses": ["ì˜ì–´"],
                    "recommendations": ["ì˜ì–´ í•™ìŠµ ì‹œê°„ì„ ëŠ˜ë¦¬ì„¸ìš”"],
                    "progress_score": 75,
                    "ai_analysis": response.text
                }
        else:
            return {
                "strengths": ["ìˆ˜í•™", "ê³¼í•™"],
                "weaknesses": ["ì˜ì–´"],
                "recommendations": ["ì˜ì–´ í•™ìŠµ ì‹œê°„ì„ ëŠ˜ë¦¬ì„¸ìš”"],
                "progress_score": 75,
                "error": "AI ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}")

@router.post("/command", summary="ìì—°ì–´ ëª…ë ¹ ì²˜ë¦¬")
async def process_natural_language_command(
    command: str = Body(...),
    session: Session = Depends(get_session),
    current_user = Depends(AuthService.get_current_active_user)
):
    """ìì—°ì–´ ëª…ë ¹ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        # ìì—°ì–´ ëª…ë ¹ì„ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸
        command_prompt = f"""
        ë‹¤ìŒ ìì—°ì–´ ëª…ë ¹ì„ JSON í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
        
        ëª…ë ¹: {command}
        
        ê°€ëŠ¥í•œ ëª…ë ¹ ìœ í˜•:
        1. í•™ìƒ ê´€ë ¨: "ê¹€ì² ìˆ˜ í•™ìƒ ì •ë³´ ë³´ì—¬ì¤˜", "í•™ìƒ ëª©ë¡ ì¡°íšŒ"
        2. ê°•ì‚¬ ê´€ë ¨: "ì´ì˜í¬ ê°•ì‚¬ ìŠ¤ì¼€ì¤„ í™•ì¸", "ê°•ì‚¬ ëª©ë¡ ì¡°íšŒ"
        3. êµì¬ ê´€ë ¨: "ìˆ˜í•™ êµì¬ ì¬ê³  í™•ì¸", "êµì¬ ëª©ë¡ ì¡°íšŒ"
        4. ìˆ˜ê°•ë£Œ ê´€ë ¨: "ë¯¸ë‚© í•™ìƒ ëª©ë¡", "ìˆ˜ê°•ë£Œ ë‚©ë¶€ í˜„í™©"
        
        ì‘ë‹µ í˜•ì‹:
        {{
            "command_type": "student|teacher|material|tuition",
            "action": "get|create|update|delete|list",
            "target": "student_name|teacher_name|material_name",
            "filters": {{}},
            "parameters": {{}}
        }}
        """
        
        # Gemini APIë¡œ ëª…ë ¹ íŒŒì‹±
        response = model.generate_content(command_prompt)
        
        if response.text:
            try:
                # JSON íŒŒì‹± ì‹œë„
                import re
                json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
                if json_match:
                    parsed_command = json.loads(json_match.group())
                else:
                    parsed_command = {
                        "command_type": "unknown",
                        "action": "unknown",
                        "target": command,
                        "filters": {},
                        "parameters": {}
                    }
                
                return {
                    "original_command": command,
                    "parsed_command": parsed_command,
                    "ai_response": response.text
                }
            except json.JSONDecodeError:
                return {
                    "original_command": command,
                    "parsed_command": {
                        "command_type": "unknown",
                        "action": "unknown",
                        "target": command,
                        "filters": {},
                        "parameters": {}
                    },
                    "ai_response": response.text
                }
        else:
            return {
                "original_command": command,
                "error": "ëª…ë ¹ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëª…ë ¹ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}") 