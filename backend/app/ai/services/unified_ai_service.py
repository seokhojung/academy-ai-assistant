from typing import Dict, Any, Optional
from sqlmodel import Session
from ..core.base_prompt import BasePrompt
from ..core.prompt_factory import PromptFactory
from ..core.context_builder import ContextBuilder
from ..core.response_validator import ResponseValidator
from ..adapters.adapter_factory import AdapterFactory
import json

class UnifiedAIService:
    """í†µí•© AI ì„œë¹„ìŠ¤ (ëª¨ë¸ ë¬´ê´€)"""
    
    def __init__(self, model_type: str, api_key: str, prompt_type: str = "optimized", **kwargs):
        self.adapter = AdapterFactory.create_adapter(model_type, api_key, **kwargs)
        self.prompt_manager = PromptFactory.create_prompt(prompt_type)
        self.context_builder = ContextBuilder()
        self.validator = ResponseValidator()
        self.max_retries = 3
        self.prompt_type = prompt_type
        
        print(f"[UnifiedAIService] {prompt_type} ì§€ì¹¨ìœ¼ë¡œ ì´ˆê¸°í™”ë¨")
    
    def switch_prompt_type(self, prompt_type: str):
        """ì§€ì¹¨ íƒ€ì… ë³€ê²½"""
        self.prompt_manager = PromptFactory.create_prompt(prompt_type)
        self.prompt_type = prompt_type
        print(f"[UnifiedAIService] ì§€ì¹¨ íƒ€ì… ë³€ê²½: {prompt_type}")
    
    def get_current_prompt_info(self) -> Dict[str, str]:
        """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì§€ì¹¨ ì •ë³´ ë°˜í™˜"""
        available_prompts = PromptFactory.get_available_prompts()
        if self.prompt_type in available_prompts:
            return {
                "type": self.prompt_type,
                "name": available_prompts[self.prompt_type]["name"],
                "description": available_prompts[self.prompt_type]["description"]
            }
        return {"type": "unknown", "name": "ì•Œ ìˆ˜ ì—†ìŒ", "description": "ì•Œ ìˆ˜ ì—†ìŒ"}
    
    def get_prompt_comparison(self) -> str:
        """ì§€ì¹¨ ë¹„êµ ë¦¬í¬íŠ¸ ë°˜í™˜"""
        return PromptFactory.compare_prompts()
    
    async def generate_response(
        self, 
        message: str, 
        session: Optional[Session] = None
    ) -> str:
        """AI ì‘ë‹µ ìƒì„± (ê²€ì¦ í¬í•¨)"""
        
        # CRUD ëª…ë ¹ ê°ì§€
        if self._is_crud_request(message):
            print(f"[UnifiedAIService] CRUD ìš”ì²­ ê°ì§€: {message}")
            return await self._handle_crud_request(message, session)
        
        for attempt in range(self.max_retries):
            try:
                print(f"[UnifiedAIService] ì‹œë„ {attempt + 1} ì‹œì‘")
                
                # 1. ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° êµ¬ì¶•
                context_data = await self.context_builder.build_context(session)
                filtered_context = self.context_builder.filter_context_by_keywords(context_data, message)
                print(f"[UnifiedAIService] ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• ì™„ë£Œ: {len(filtered_context)} í•­ëª©")
                
                # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
                system_prompt = self.prompt_manager.get_full_prompt(filtered_context, message)
                optimized_prompt = self.adapter.optimize_prompt(system_prompt)
                print(f"[UnifiedAIService] í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {len(optimized_prompt)} ë¬¸ì")
                
                # 3. ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
                formatted_prompt = self.adapter.format_prompt(optimized_prompt, filtered_context, message)
                print(f"[UnifiedAIService] í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… ì™„ë£Œ: {len(formatted_prompt)} ë©”ì‹œì§€")
                
                # 4. AI ì‘ë‹µ ìƒì„±
                print(f"[UnifiedAIService] AI ì‘ë‹µ ìƒì„± ì‹œì‘...")
                raw_response = await self.adapter.generate_response(formatted_prompt)
                print(f"[UnifiedAIService] AI ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(raw_response)} ë¬¸ì")
                print(f"[UnifiedAIService] AI ì›ë³¸ ì‘ë‹µ: {raw_response[:200]}...")
                
                response = self.adapter.parse_response(raw_response)
                print(f"[UnifiedAIService] ì‘ë‹µ íŒŒì‹± ì™„ë£Œ: {len(response)} ë¬¸ì")
                
                # 5. ì‘ë‹µ ê²€ì¦
                is_valid, error_message = self.validator.validate_response(response, context_data)
                
                if is_valid:
                    print(f"[UnifiedAIService] ì‘ë‹µ ê²€ì¦ ì„±ê³µ (ì‹œë„ {attempt + 1})")
                    return response
                else:
                    print(f"[UnifiedAIService] ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {error_message}")
                    
                    # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ë” ê°•í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                    if attempt < self.max_retries - 1:
                        system_prompt = self._get_stronger_prompt(filtered_context, message, error_message)
                        continue
                    else:
                        return self._get_fallback_response(message, error_message)
                        
            except Exception as e:
                print(f"[UnifiedAIService] ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt + 1}): {e}")
                if attempt == self.max_retries - 1:
                    return f"AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    async def generate_response_stream(
        self, 
        message: str, 
        session: Optional[Session] = None
    ):
        """AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
        try:
            print(f"[UnifiedAIService] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘")
            
            # 1. ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° êµ¬ì¶•
            context_data = await self.context_builder.build_context(session)
            filtered_context = self.context_builder.filter_context_by_keywords(context_data, message)
            print(f"[UnifiedAIService] ìŠ¤íŠ¸ë¦¬ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• ì™„ë£Œ: {len(filtered_context)} í•­ëª©")
            
            # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = self.prompt_manager.get_full_prompt(filtered_context, message)
            optimized_prompt = self.adapter.optimize_prompt(system_prompt)
            
            # 3. ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
            formatted_prompt = self.adapter.format_prompt(optimized_prompt, filtered_context, message)
            
            # 4. AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            print(f"[UnifiedAIService] AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹œì‘...")
            async for chunk in self.adapter.generate_response_stream(formatted_prompt):
                yield chunk
                
        except Exception as e:
            print(f"[UnifiedAIService] ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
            yield f"AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _is_crud_request(self, message: str) -> bool:
        """CRUD ëª…ë ¹ì–´ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        crud_keywords = [
            # ì˜ì–´ í‚¤ì›Œë“œ
            "create", "read", "update", "delete", "add", "remove", "modify", "edit",
            # í•œêµ­ì–´ í‚¤ì›Œë“œ
            "ìƒì„±", "ì¶”ê°€", "ë“±ë¡", "ë§Œë“¤", "ì¡°íšŒ", "ë³´ê¸°", "í™•ì¸", "ìˆ˜ì •", "ë³€ê²½", "í¸ì§‘", "ì‚­ì œ", "ì œê±°", "ì§€ìš°"
        ]
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in crud_keywords)
    
    async def _handle_crud_request(self, message: str, session: Optional[Session]) -> str:
        """CRUD ëª…ë ¹ì–´ì— ëŒ€í•œ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        print(f"[UnifiedAIService] CRUD ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: {message}")
        
        try:
            # ëª…ë ¹ì–´ ì¶”ì¶œ
            command = message.lower()
            if "create" in command:
                print(f"[UnifiedAIService] CRUD: Create ëª…ë ¹ì–´ ê°ì§€")
                # ì˜ˆì‹œ: ìƒˆë¡œìš´ ë°ì´í„° ìƒì„± ë¡œì§
                # ì´ ë¶€ë¶„ì€ ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                # ì˜ˆ: session.add(new_data)
                # session.commit()
                return json.dumps({
                    "type": "text",
                    "content": f"Create ëª…ë ¹ì–´ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°: {message}"
                }, ensure_ascii=False)
            elif "read" in command:
                print(f"[UnifiedAIService] CRUD: Read ëª…ë ¹ì–´ ê°ì§€")
                # ì˜ˆì‹œ: ë°ì´í„° ì¡°íšŒ ë¡œì§
                # ì´ ë¶€ë¶„ì€ ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                # ì˜ˆ: session.query(DataModel).all()
                return json.dumps({
                    "type": "text",
                    "content": f"Read ëª…ë ¹ì–´ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°: {message}"
                }, ensure_ascii=False)
            elif "update" in command:
                print(f"[UnifiedAIService] CRUD: Update ëª…ë ¹ì–´ ê°ì§€")
                # ì˜ˆì‹œ: ë°ì´í„° ì—…ë°ì´íŠ¸ ë¡œì§
                # ì´ ë¶€ë¶„ì€ ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                # ì˜ˆ: session.query(DataModel).filter(DataModel.id == 1).update(new_data)
                # session.commit()
                return json.dumps({
                    "type": "text",
                    "content": f"Update ëª…ë ¹ì–´ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°: {message}"
                }, ensure_ascii=False)
            elif "delete" in command:
                print(f"[UnifiedAIService] CRUD: Delete ëª…ë ¹ì–´ ê°ì§€")
                # ì˜ˆì‹œ: ë°ì´í„° ì‚­ì œ ë¡œì§
                # ì´ ë¶€ë¶„ì€ ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                # ì˜ˆ: session.query(DataModel).filter(DataModel.id == 1).delete()
                # session.commit()
                return json.dumps({
                    "type": "text",
                    "content": f"Delete ëª…ë ¹ì–´ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°: {message}"
                }, ensure_ascii=False)
            else:
                return json.dumps({
                    "type": "text",
                    "content": f"ì•Œ ìˆ˜ ì—†ëŠ” CRUD ëª…ë ¹ì–´ì…ë‹ˆë‹¤: {message}"
                }, ensure_ascii=False)
        except Exception as e:
            print(f"[UnifiedAIService] CRUD ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return json.dumps({
                "type": "text",
                "content": f"CRUD ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }, ensure_ascii=False)
    
    def _get_stronger_prompt(self, context_data: Dict[str, Any], message: str, error_message: str) -> str:
        """ë” ê°•í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
        {self.prompt_manager.get_full_prompt(context_data, message)}
        
        ## ğŸš¨ ì´ì „ ì‘ë‹µ ì˜¤ë¥˜ ìˆ˜ì • ìš”ì²­
        ì˜¤ë¥˜: {error_message}
        
        ìœ„ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
    
    def _get_fallback_response(self, message: str, error_message: str) -> str:
        """í´ë°± ì‘ë‹µ ìƒì„±"""
        return json.dumps({
            "type": "text",
            "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}"
        }, ensure_ascii=False) 